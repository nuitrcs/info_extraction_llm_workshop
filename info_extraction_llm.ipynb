{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Information From Text With LLMs\n",
        "\n",
        "Information extraction is a key part of computational text analysis. üìöüíª\n",
        "\n",
        "Specifically, information extraction consists in extracting structured information from text. Often, you want to extract specific types of information such as named entities or their relationships. Named entities can be persons, locations, organizations, dates, etc.\n",
        "\n",
        "Information extraction can be very useful for your research by helping you process and make sense of text data.\n",
        "\n",
        "There are many methods for information extraction. This workshop provides a broad overview of different approaches, their pros/cons and use cases, and offers some specific advice on when and how to use large language models (LLMs) for information extraction.\n",
        "\n",
        "We'll start with approaches other than LLMs first to provide the context where LLMs fit and to get a better understanding of the pros and cons of LLMs. ü¶æ"
      ],
      "metadata": {
        "id": "B2c-XHGxNIMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "Q2a68tVvmLD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_ZA21ZJk5aU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # to use dataframes\n",
        "import re # to use regular expressions\n",
        "import spacy # for NLP, here named entity recognition\n",
        "from openai import OpenAI # to use OpenAI API\n",
        "import requests # here, to get txt files from GitHub\n",
        "# To use OpenAI API's key:\n",
        "# https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0\n",
        "from google.colab import userdata\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data\n",
        "\n",
        "This workshop uses abstracts about \"environmental sustainability\" collected from [OpenAlex](https://openalex.org/). (If you're curious, [this is the script used for data collection](https://github.com/emiliolehoucq/trainings/blob/main/data/openalex_data_collection.ipynb).) üå±\n",
        "\n",
        "Let's first read the data."
      ],
      "metadata": {
        "id": "y3jBq_qFmMoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/emiliolehoucq/trainings/refs/heads/main/data/open_alex_data.csv')"
      ],
      "metadata": {
        "id": "qyg0BxmQk9Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore data\n",
        "\n",
        "Let's take a look at the data."
      ],
      "metadata": {
        "id": "6wF7jqoumN3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "NsxhcQGYlBDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "FTXgxFN9lCGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "01a3y6VslD-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed used throughout the notebook\n",
        "SEED = 123\n",
        "\n",
        "# Iterate over a sample of the data\n",
        "for index, row in df.sample(10, random_state = SEED).iterrows():\n",
        "  # This is for readability\n",
        "  print(\"==============================================================\")\n",
        "  # Print some info for exploration\n",
        "  print(f\"Title: {row['title']}\")\n",
        "  print(f\"Length abstract: {len(row['abstract'])}\")\n",
        "  print(f\"Abstract:\\n{row['abstract']}\")\n",
        "  print(\"==============================================================\\n\")"
      ],
      "metadata": {
        "id": "SEWx5s-ZlMdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview of approaches\n",
        "\n",
        "This section provides an overview of different approaches to information extraction, their pros/cons, and their use cases. üë®üèΩ‚Äçüè´\n",
        "\n",
        "*While the approaches are discussed separately, in practice it can be useful to combine them.*\n",
        "\n",
        "As previously mentioned, we'll leave LLMs for the end of this section to provide better context first. We'll start with keyword search, then regular expressions, then pre-trained entity recognition models, and finally LLMs.\n",
        "\n",
        "### Keyword search üîç\n",
        "\n",
        "Definition: searching for a predefined term in a text.\n",
        "\n",
        "Pros: can be fast and easy to implement and you know exactly what your code is doing.\n",
        "\n",
        "Cons: can be prone to false positives/negatives and lacks a more sophisticated understanding of language.\n",
        "\n",
        "Use cases: particularly useful when there is a well-defined set number of terms that you're looking for (e.g., company names). You can also use keyword search to filter documents."
      ],
      "metadata": {
        "id": "5uyw-2wZmP_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set context window to be used later\n",
        "CONTEXT_WINDOW = 75\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    abstract = row['abstract']\n",
        "    title = row['title']\n",
        "\n",
        "    search_term = \"climate change\"\n",
        "    # Lowercase abstract\n",
        "    lower_abstract = abstract.lower()\n",
        "\n",
        "    start_index = 0  # Keep track of where to search from\n",
        "\n",
        "    while True:\n",
        "        # Find the next occurrence of search term\n",
        "        # find() returns the index of the first occurrence of a subtring in a string\n",
        "        # https://www.geeksforgeeks.org/python-string-find/\n",
        "        match_index = lower_abstract.find(search_term, start_index)\n",
        "\n",
        "        # If search term not found\n",
        "        if match_index == -1:\n",
        "            break  # Exit loop if no more matches are found\n",
        "\n",
        "        print(\"===============================================================\")\n",
        "        print(f\"Title: {title}\")\n",
        "\n",
        "        # Get the match\n",
        "        match = lower_abstract[match_index:match_index + len(search_term)]\n",
        "        print(f\"Match: {match}\")\n",
        "\n",
        "        # Get the characters around the match\n",
        "        start = max(0, match_index - CONTEXT_WINDOW)  # Ensure start index is not negative\n",
        "        end = min(len(abstract), match_index + len(search_term) + CONTEXT_WINDOW)  # Ensure end index is within bounds\n",
        "        context = abstract[start:end]\n",
        "\n",
        "        print(f\"Context for match: {context}\")\n",
        "        print(\"==============================================================\\n\")\n",
        "\n",
        "        # Move start_index forward to continue searching after the current match\n",
        "        start_index = match_index + len(search_term)"
      ],
      "metadata": {
        "id": "CcQRhJsGr4F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above I was just printing the output to show you. In your research, you'll probably want to save the output. Here's one way to do it:"
      ],
      "metadata": {
        "id": "aGp3y8571KwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store the results\n",
        "results = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    abstract = row['abstract']\n",
        "    title = row['title']\n",
        "\n",
        "    search_term = \"climate change\"\n",
        "    lower_abstract = abstract.lower()\n",
        "\n",
        "    start_index = 0\n",
        "\n",
        "    while True:\n",
        "        match_index = lower_abstract.find(search_term, start_index)\n",
        "\n",
        "        if match_index == -1:\n",
        "            break\n",
        "\n",
        "        match = lower_abstract[match_index:match_index + len(search_term)]\n",
        "\n",
        "        start = max(0, match_index - CONTEXT_WINDOW)\n",
        "        end = min(len(abstract), match_index + len(search_term) + CONTEXT_WINDOW)\n",
        "        context = abstract[start:end]\n",
        "\n",
        "        # Append result to the list\n",
        "        results.append({\n",
        "            \"title\": title,\n",
        "            \"abstract\": abstract,\n",
        "            \"match\": match,\n",
        "            \"context\": context\n",
        "        })\n",
        "\n",
        "        start_index = match_index + len(search_term)\n",
        "\n",
        "print(\"This cell run successfully!\")"
      ],
      "metadata": {
        "id": "N0oW_70w1LGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first two elements of the list\n",
        "results[:2]"
      ],
      "metadata": {
        "id": "9wSjpr1f12gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list to DataFrame\n",
        "output_df = pd.DataFrame(results)\n",
        "\n",
        "# Take a look at the first two rows of the dataframe\n",
        "output_df.head(2)"
      ],
      "metadata": {
        "id": "ykLMdau_14jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "output_df.to_csv(\"matches.csv\", index=False)"
      ],
      "metadata": {
        "id": "uRB1JKe614Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**\n",
        "\n",
        "Using the approach above, search for \"water\"."
      ],
      "metadata": {
        "id": "BH5LyNHvRfIz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXfNz-MQaECX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regular expressions üß©\n",
        "\n",
        "Definition: using patterns to match information in a text.\n",
        "\n",
        "Pros: similarly to keyword search, you understand exactly what your code is doing. Regular expressions are more flexible than keyword search.\n",
        "\n",
        "Cons: they can be difficult to write for complex patterns and lack a more sophisticated understanding of language.\n",
        "\n",
        "Use cases: particularly useful when the information follows a well-defined format (e.g., dates, phone numbers). Regular expressions can also be useful to clean text data."
      ],
      "metadata": {
        "id": "cfKSGHBcvPfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_WINDOW = 75\n",
        "\n",
        "# Pattern to search for\n",
        "# \\d{1,3} - Matches between 1 and 3 digits\n",
        "# \\s? - Matches an optional whitespace character\n",
        "# (%|percent|percentage) - Matches either the % symbol, the word percent, or the word percentage\n",
        "# \\s - Matches a mandatory space\n",
        "# (reduction|increase|decrease|growth|drop|improvement|change) - Match one of the specified change-related keywords\n",
        "pattern = r\"\\d{1,3}\\s?(%|percent|percentage)\\s(reduction|increase|decrease|growth|drop|improvement|change)\"\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  abstract = row['abstract']\n",
        "  # Find all occurrences of pattern and extract surrounding context\n",
        "  # re.finditer() searches for all matches of a pattern in a string and returns them as an iterator\n",
        "  # https://www.geeksforgeeks.org/re-finditer-in-python/\n",
        "  matches = re.finditer(pattern, abstract, re.IGNORECASE)\n",
        "  # Iterate over matches\n",
        "  for each_match in matches:\n",
        "    print(\"===============================================================\")\n",
        "    print(f\"Title: {row['title']}\")\n",
        "    print(each_match.group())\n",
        "    # Get the characters around the match\n",
        "    start = max(0, each_match.start() - CONTEXT_WINDOW)  # Ensure start index is not negative\n",
        "    end = min(len(abstract), each_match.end() + CONTEXT_WINDOW)  # Ensure end index is within bounds\n",
        "    context = abstract[start:end]\n",
        "    print(f\"Context for match: {context}\")\n",
        "    print(\"==============================================================\\n\")"
      ],
      "metadata": {
        "id": "7vgVlAQWsl8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**\n",
        "\n",
        "Using the approach above, search for years."
      ],
      "metadata": {
        "id": "zwFDYABjR7rv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "35qy1Ob7aFJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-trained entity recognition models üèãüèΩ‚Äç‚ôÇÔ∏è\n",
        "\n",
        "Definition: machine learning models that are trained to identify and classify entities such as persons, locations, organizations, years, etc.\n",
        "\n",
        "Pros: they have a more sophisticated understanding of language and are easy to use off the shelf.\n",
        "\n",
        "Cons: they can misclassify entities and have biases. They may not be pre-trained for the entity you need. You don't necessarily understand exactly what the model is doing.\n",
        "\n",
        "Use cases: particularly useful for common entities if there is not a well-defined set list of terms or a clear pattern."
      ],
      "metadata": {
        "id": "GesFThZWv7uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the \"en_core_web_sm\" pre-trained language model (that does tokenization, part-of-speech tagging, named entitity recognition)\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "WelGwndTzNbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note 1: spaCy is not the only place where you can get pre-trained entity recognition models. For example, you can also look for models in [Hugging Face](https://huggingface.co/models).\n",
        "\n",
        "Note 2: of course, you can always train your own model or fine-tune an existing one."
      ],
      "metadata": {
        "id": "LrSeGQ_ObP1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_abstract = df[\"abstract\"][272]\n",
        "test_abstract"
      ],
      "metadata": {
        "id": "6xkDowljv9Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Doc object, which contains the processed text (including tokens, linguistic annotations, and recognized entities)\n",
        "doc = nlp(test_abstract)"
      ],
      "metadata": {
        "id": "IB6EOQKczlc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visually highlight named entities in text\n",
        "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "id": "Gyec2PtTuZfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü§Øü§Øü§Øü§Øü§Ø\n",
        "\n",
        "While that visual representation is fun, in the context of your research you're more likely to use code like this:"
      ],
      "metadata": {
        "id": "yoOVCiRluuaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the named entities\n",
        "for ent in doc.ents:\n",
        "  print(\"===============================================================\")\n",
        "  print(f\"Text of the entity: {ent.text}\")\n",
        "  print(f\"Label of the entity: {ent.label_}\")\n",
        "  print(f\"Start character of the entity: {ent.start_char}\")\n",
        "  print(f\"End character of the entity: {ent.end_char}\")\n",
        "  print(\"==============================================================\\n\")"
      ],
      "metadata": {
        "id": "pIk7hpmhyz07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df.sample(20, random_state=SEED).iterrows():\n",
        "  abstract = row['abstract']\n",
        "  for ent in nlp(abstract).ents:\n",
        "    if ent.label_ == \"ORG\":\n",
        "      print(\"===============================================================\")\n",
        "      print(f\"Title of the paper: {row['title']}\")\n",
        "      print(f\"Text of the organization: {ent.text}\")\n",
        "      start = max(0, ent.start_char - CONTEXT_WINDOW)  # Ensure start index is not negative\n",
        "      end = min(len(abstract), ent.end_char + CONTEXT_WINDOW)  # Ensure end index is within bounds\n",
        "      context = abstract[start:end]\n",
        "      print(f\"Context for match: {context}\")\n",
        "      print(\"==============================================================\\n\")"
      ],
      "metadata": {
        "id": "_OD1MsyP2h34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**\n",
        "\n",
        "Using the approach above, search for persons."
      ],
      "metadata": {
        "id": "588hciMQSFcb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1qE4QDGaG5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLMs ü§ñ\n",
        "\n",
        "Definition: large machine learning models trained for various natural language processing tasks.\n",
        "\n",
        "Pros: they have a pretty sophisticated understanding of language and can be very flexible.\n",
        "\n",
        "Cons: you don't necessarily understand what the model is doing, the output can vary across model calls, they have biases, they don't necessarily follow your instructions, and they can hallucinate. They can also be computationally intensive.\n",
        "\n",
        "Use cases: particularly useful for complex tasks for which there is not a well-defined set list of terms, a clear pattern, or a pre-trained model.\n",
        "\n",
        "----\n",
        "\n",
        "Note 1: for the purposes of this workshop, we'll mostly use [HuggingChat](https://huggingface.co/chat/) with `meta-llama/Llama-3.3-70B-Instruct`. HuggingChat has the advantage that we can set the system prompt. Also, you can try different models with the same prompt.\n",
        "\n",
        "Note 2: A system prompt refers to the instructions that you give to the LLM specifying how it should behave across all interactions. In contrast, a user prompt is a specific instruction that you give to the LLM for a particular interaction.\n",
        "\n",
        "Let's use this abstract as example:"
      ],
      "metadata": {
        "id": "AaWeIyTu1Eqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_abstract = df[\"abstract\"][954]\n",
        "test_abstract"
      ],
      "metadata": {
        "id": "6tmE9hXJo92C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to extract the main point of the article from the abstract. We're not asking the LLM to infer what the main point is. We're asking the LLM to \"understand\" the abstract, find where the main point is, and extract a direct citation for us.\n",
        "\n",
        "Asking the LLM for the main point is a good example of what an LLM can do that other approaches can't do or can't do as well. To extract the main point, the LLM needs to understand language in a more sophisticated way to know where the main point is. It's not always as easy as \"The argument/main finding of this article is ...\" or \"This article demonstrates that ...\".\n",
        "\n",
        "Let's try it out! üéâ\n",
        "\n",
        "Here's the system prompt:\n",
        "\n",
        "```\n",
        "YOUR ROLE\n",
        "\n",
        "You are a diligent, careful, and detailed-oriented assistant for information detection and extraction.\n",
        "\n",
        "You value accuracy: when the user asks you to extract certain information from a given text, you will adhere to what is directly mentioned in the text and the extraction criteria.\n",
        "\n",
        "You value conciseness: your responses will be very concise, because they will be stored as values in a dataset. These responses will also strictly follow formatting conventions specified in the extraction prompt.\n",
        "\n",
        "STEPS TO FOLLOW\n",
        "\n",
        "First, read the given text carefully.\n",
        "\n",
        "Second, review the extraction criteria and think about what the answer is based on the given text.\n",
        "\n",
        "Third, explain your reasoning.\n",
        "\n",
        "Finally, provide your answer.\n",
        "\n",
        "FORMAT FOR YOUR ANSWER\n",
        "\n",
        "Reasoning: <explanation of your reasoning>\n",
        "\n",
        "My answer is: <concise answer strictly following the instructions provided in the extraction prompt>\n",
        "```\n",
        "\n",
        "And here's the user prompt:\n",
        "\n",
        "```\n",
        "Below I will provide the abstract of an article.\n",
        "\n",
        "Based on the text of the abstract, give me a direct citation with the main point of the article (if available).\n",
        "\n",
        "Instead of summarizing or infering something from the article, I want you to give me a direct citation (if available).\n",
        "\n",
        "If you are not sure, respond \"UNSURE\".\n",
        "\n",
        "Here is the abstract:\n",
        "```\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "Using the approach above, extract the method(s) used in the article."
      ],
      "metadata": {
        "id": "AQMmx6gfTPlz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u6t9W7t5aIdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### OpenAI API\n",
        "\n",
        "For this workshop, we're mostly using HuggingChat. However, in your research you'll want to query models through an API (or a way for software to communicate with each other).\n",
        "\n",
        "Let's see an example using the [OpenAI API](https://platform.openai.com/docs/overview). (You can see the [billing here](https://platform.openai.com/settings/organization/billing/overview), [get API keys here](https://platform.openai.com/api-keys), and [check your usage here](https://platform.openai.com/settings/organization/usage).)\n",
        "\n",
        "Don't worry if you're not familiar with APIs. While this workshop cannot get in the details, they're not complicated to use and [we're happy to help you](https://app.smartsheet.com/b/form/2f2ec327e6164f83b588b7bbe2e2b56f). Below is just an example.\n",
        "\n",
        "‚ö†Ô∏è **Keep in mind that you cannot use OpenAI's API with private data. Make sure to check [Northwestern University's guidance on the use of generative AI](https://www.it.northwestern.edu/about/policies/guidance-on-the-use-of-generative-ai.html).** Feel free to [submit a consult request](https://app.smartsheet.com/b/form/2f2ec327e6164f83b588b7bbe2e2b56f) if you have any questions about this in your research.\n",
        "\n",
        "OpenAI API's is not the only option. With private data, you can consider using [Microsoft Azure OpenAI Services](https://services.northwestern.edu/TDClient/30/Portal/KB/ArticleDet?ID=2546). In your local machine, you can use [Ollama](https://ollama.com/), including [with Python](https://github.com/ollama/ollama-python). You can also use Ollama on Quest (and apparently [on Google Colab](https://adasci.org/a-practitioners-guide-to-running-ollama-models-in-colab-collama/#:~:text=Unlock%20the%20power%20of%20AI,Run%20advanced%20language%20models%20effortlessly.) to try it out). Again, [we're happy to help you](https://app.smartsheet.com/b/form/2f2ec327e6164f83b588b7bbe2e2b56f)!"
      ],
      "metadata": {
        "id": "aErCcHG93veJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0\n",
        "\n",
        "# Set API key as environmental variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "ZBoK08ImysJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create OpenAI client\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "2_NiROOd4b29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to query model\n",
        "def get_model_response(prompt_system, prompt_user):\n",
        "  \"\"\"\n",
        "  Function to get a response from a model.\n",
        "\n",
        "  Inputs:\n",
        "  - prompt_system (str): system prompt\n",
        "  - prompt_user (str): user prompt\n",
        "\n",
        "  Outputs:\n",
        "  - response (str): response from the model\n",
        "\n",
        "  https://platform.openai.com/docs/quickstart?language=python\n",
        "  \"\"\"\n",
        "  # Get response from model\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\", # https://openai.com/api/pricing/\n",
        "      messages=[{\"role\": \"system\", \"content\": prompt_system}, {\"role\": \"user\", \"content\": prompt_user}]\n",
        "  )\n",
        "\n",
        "  # Return response\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "TlZoRapl4mnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get the prompts that we have already used:"
      ],
      "metadata": {
        "id": "gHilF9EuVaWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_system = requests.get(\"https://raw.githubusercontent.com/nuitrcs/info_extraction_llm_workshop/refs/heads/main/prompt_system.txt\").text\n",
        "prompt_system"
      ],
      "metadata": {
        "id": "DsBu7BUHGd-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_main_point = requests.get(\"https://raw.githubusercontent.com/nuitrcs/info_extraction_llm_workshop/refs/heads/main/prompt_main_point.txt\").text\n",
        "prompt_main_point"
      ],
      "metadata": {
        "id": "7PGIcURdHxPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's query the model:"
      ],
      "metadata": {
        "id": "1SXoN9clVeqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Uncomment to not keep sending requests!\n",
        "\n",
        "# for index, row in df.sample(5, random_state=SEED).iterrows():\n",
        "#   # Put the prompt and the abstract together\n",
        "#   prompt_user = prompt_main_point + '\\n' + row['abstract']\n",
        "#   print(\"===============================================================\")\n",
        "#   print(\"===============================================================\")\n",
        "#   print(f\"Title of the paper: {row['title']}\")\n",
        "#   print(\"---------------------------------------------------------------\")\n",
        "#   print(f\"Prompt and abstract:\\n\\n\\n{prompt_user}\")\n",
        "#   print(\"---------------------------------------------------------------\")\n",
        "#   # Use the function created above to get response from the model\n",
        "#   print(f\"Response from the model:\\n\\n\\n{get_model_response(prompt_system, prompt_user)}\")\n",
        "#   print(\"==============================================================\")\n",
        "#   print(\"==============================================================\\n\\n\")"
      ],
      "metadata": {
        "id": "zo_8AvOPHA5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**\n",
        "\n",
        "This section discussed various approaches to information extraction: keyword search, regular expressions, pre-trained entity recognition models, and LLMs. Below are several examples of information extraction tasks in research. For each scenario, think about what approach you'd use and why. üß†\n",
        "\n",
        "a) You are studying historical documents and need to extract references to specific historical figures, even when they are referred to indirectly (e.g., \"the first president\" referring to George Washington).\n",
        "\n",
        "b) You need to extract standardized legal case citations (e.g., *Marbury v. Madison, 5 U.S. 137 (1803)*) from legal documents.\n",
        "\n",
        "c) You are analyzing political speeches and want to identify mentions of specific policies (e.g., ‚ÄúMedicare for All‚Äù or ‚ÄúGreen New Deal‚Äù).\n",
        "\n",
        "d) You need to extract company names and stock ticker symbols from financial news articles.\n",
        "\n",
        "e) You are reviewing electronic health records to extract patient symptoms, even when they are described in different ways (e.g., ‚Äústomach pain,‚Äù ‚Äúabdominal discomfort,‚Äù ‚Äúache in the belly‚Äù).\n",
        "\n",
        "f) You are studying sentiment in classic novels and need to identify passages that express themes of love and betrayal.\n",
        "\n",
        "g) You are extracting inflation rates and GDP figures from economic reports.\n",
        "\n",
        "h) You need to extract mentions of environmental disasters (e.g., ‚Äúoil spill,‚Äù ‚Äúwildfire‚Äù) from news reports.\n",
        "\n",
        "i) You are scanning news articles to extract quotes from politicians.\n",
        "\n",
        "## Best practices when using LLMs for information extraction\n",
        "\n",
        "So far, this workshop has contextualized LLMs as one approach for information extraction among others and showed some examples of how you can use LLMs. This section discusses some best practices when using LLMs for information extraction. ü§ì\n",
        "\n",
        "As with other aspects of LLMs, these are some preliminary ideas, but there is some uncertainty and things are evolving quickly. üí®\n",
        "\n",
        "- **Think about the right approach**\n",
        "  - *Try simpler approaches* first, or at least consider them.\n",
        "  - *Consider combining the LLM approach with simpler approaches* as relevant.\n",
        "- **Model selection**\n",
        "  - *Close vs. open source*. Close source models can be easier to use, although not necessarily. Some close source models can have better performance, but not necessarily. Open source models are \"free\" to use. Open source models are better for reproducibility.\n",
        "  - *Model size*. Depending on the size of the text that you need to feed into the LLM and the complexity of your task, you may be able to use a smaller vs. larger model. Smaller models are faster to run, can fit in your local machine or on Quest, and have less of an environmental impact. Larger models can have better performance, particularly without fine tuning.\n",
        "  - *Experiment with a couple of models* and see how they perform in your specific task, including accuracy, biases, instruction following, etc.\n",
        "- **Prompts**\n",
        "  - *Follow prompt engineering guidelines* such as [these ones](https://github.com/nuitrcs/CoDEx-LLM-Workshop/blob/main/prompt_engineering_cheat_sheet.pdf). There are many resources about prompt engineering online (e.g., [this free course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)). Model developers also provide some guidelines specfic to their models (e.g., [OpenAI](https://platform.openai.com/docs/guides/prompt-engineering) and [Meta](https://www.llama.com/docs/how-to-guides/prompting/)). For information extraction, these are some tips that I have found helpful:\n",
        "    - In describing the role of the model, emphasize the importance of accuracy, details, and conciseness.\n",
        "    - Tell the model to read, review the extraction criteria, explain the reasoning, and give an answer.\n",
        "    - Ask the model to format the answer in a way that works for you, potentially asking for the reasoning in addition to the answer.\n",
        "    - Start with simple prompts and tweak them as you see fit to solve specific problems.\n",
        "    - Tell the model the types and range of answers that you want.\n",
        "    - Give the model the option to respond \"unsure\"/\"missing\".\n",
        "    - Potentially give the model specific extraction criteria.\n",
        "    - Potentially give the model examples of the behavior you want.\n",
        "  - *Keep a record* of the prompts you tried, how they performed, and why you changed them.\n",
        "  - *Organize prompts* in a way that serves your project over time.\n",
        "- **Querying the model**\n",
        "  - *Check the response*, specifically check that the model's output is in the correct format. If you asked the model for a direct citation from the text, you could also check that the response is actually in the text.\n",
        "  - *Query the model several times*, record all responses, and select the response that is given at least certain proportion of times.\n",
        "  - *Document* the model and version/date that you used.\n",
        "\n",
        "----\n",
        "\n",
        "[Here is an example of some of these ideas](https://github.com/nuitrcs/info_extraction_llm_workshop/tree/main/example). üí°\n",
        "\n",
        "----\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "Using `meta-llama/Llama-3.3-70B-Instruct` on HuggingChat, run the following examples. What do you notice?\n",
        "\n",
        "1)\n",
        "\n",
        "Start with this sytem prompt:\n",
        "\n",
        "```\n",
        "You are a helpful assistant.\n",
        "```\n",
        "\n",
        "Try these prompts:\n",
        "\n",
        "a)\n",
        "\n",
        "```\n",
        "tell me the importance of this paper This study aims to show that the effectiveness of corporate governance in improving firms‚Äô environmental sustainability depends on national institutional context. Using a sample 210 firms from 14 countries North America and Europe, our findings regulatory pressures discourage independent directors separate board chairs promote whereas normative have opposite effect for these two mechanisms. We also found positive moderating relation cognitive directors. make unique contribution literature by combining factors explain sustainability. Although there is growing consensus institutions matter governance, has been little research how may moderate relationship between mechanisms Copyright ¬© 2014 John Wiley &amp; Sons, Ltd ERP Environment\n",
        "```\n",
        "\n",
        "b)\n",
        "\n",
        "```\n",
        "tell me the contribution of this paper This study aims to show that the effectiveness of corporate governance in improving firms‚Äô environmental sustainability depends on national institutional context. Using a sample 210 firms from 14 countries North America and Europe, our findings regulatory pressures discourage independent directors separate board chairs promote whereas normative have opposite effect for these two mechanisms. We also found positive moderating relation cognitive directors. make unique contribution literature by combining factors explain sustainability. Although there is growing consensus institutions matter governance, has been little research how may moderate relationship between mechanisms Copyright ¬© 2014 John Wiley &amp; Sons, Ltd ERP Environment\n",
        "```\n",
        "\n",
        "c)\n",
        "\n",
        "```\n",
        "tell me the contribution of this paper to the literature This study aims to show that the effectiveness of corporate governance in improving firms‚Äô environmental sustainability depends on national institutional context. Using a sample 210 firms from 14 countries North America and Europe, our findings regulatory pressures discourage independent directors separate board chairs promote whereas normative have opposite effect for these two mechanisms. We also found positive moderating relation cognitive directors. make unique contribution literature by combining factors explain sustainability. Although there is growing consensus institutions matter governance, has been little research how may moderate relationship between mechanisms Copyright ¬© 2014 John Wiley &amp; Sons, Ltd ERP Environment\n",
        "```\n",
        "\n",
        "d)\n",
        "\n",
        "```\n",
        "tell me the main contribution of this paper to the literature This study aims to show that the effectiveness of corporate governance in improving firms‚Äô environmental sustainability depends on national institutional context. Using a sample 210 firms from 14 countries North America and Europe, our findings regulatory pressures discourage independent directors separate board chairs promote whereas normative have opposite effect for these two mechanisms. We also found positive moderating relation cognitive directors. make unique contribution literature by combining factors explain sustainability. Although there is growing consensus institutions matter governance, has been little research how may moderate relationship between mechanisms Copyright ¬© 2014 John Wiley &amp; Sons, Ltd ERP Environment\n",
        "```\n",
        "\n",
        "e)\n",
        "\n",
        "```\n",
        "Below I will provide the abstract of an article.\n",
        "\n",
        "Based on the text of the abstract, tell me the main contribution of the article to the literature.\n",
        "\n",
        "If you are not sure, respond \"UNSURE\".\n",
        "\n",
        "Here is the abstract:\n",
        "\n",
        "This study aims to show that the effectiveness of corporate governance in improving firms‚Äô environmental sustainability depends on national institutional context. Using a sample 210 firms from 14 countries North America and Europe, our findings regulatory pressures discourage independent directors separate board chairs promote whereas normative have opposite effect for these two mechanisms. We also found positive moderating relation cognitive directors. make unique contribution literature by combining factors explain sustainability. Although there is growing consensus institutions matter governance, has been little research how may moderate relationship between mechanisms Copyright ¬© 2014 John Wiley &amp; Sons, Ltd ERP Environment\n",
        "```\n",
        "\n",
        "2)\n",
        "\n",
        "Change to this system prompt and try the last prompt again:\n",
        "\n",
        "```\n",
        "YOUR ROLE\n",
        "\n",
        "You are a diligent, careful, and detailed-oriented assistant for information detection and extraction.\n",
        "\n",
        "You value accuracy: when the user asks you to extract certain information from a given text, you will adhere to what is directly mentioned in the text and the extraction criteria.\n",
        "\n",
        "You value conciseness: your responses will be very concise, because they will be stored as values in a dataset. These responses will also strictly follow formatting conventions specified in the extraction prompt.\n",
        "\n",
        "STEPS TO FOLLOW\n",
        "\n",
        "First, read the given text carefully.\n",
        "\n",
        "Second, review the extraction criteria and think about what the answer is based on the given text.\n",
        "\n",
        "Third, explain your reasoning.\n",
        "\n",
        "Finally, provide your answer.\n",
        "\n",
        "FORMAT FOR YOUR ANSWER\n",
        "\n",
        "Reasoning: <explanation of your reasoning>\n",
        "\n",
        "My answer is: <concise answer strictly following the instructions provided in the extraction prompt>\n",
        "```\n",
        "\n",
        "## Bonus exercise\n",
        "\n",
        "Use the `get_clean_wikipedia_text` function below to get the text of a Wikipedia article that's of interest to you. Think about some information that you could extract from the text and try different approaches. Consider their pros and cons, try implementing them, and see what you get. ‚ñ∂Ô∏è"
      ],
      "metadata": {
        "id": "u192XL__sUfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia-api"
      ],
      "metadata": {
        "id": "VLDHCaGjLfbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi\n",
        "\n",
        "def get_clean_wikipedia_text(url):\n",
        "    \"\"\"\n",
        "    Fetches and returns the clean text of a Wikipedia page from the provided URL.\n",
        "\n",
        "    Args:\n",
        "        url (str): The full URL of the Wikipedia page.\n",
        "\n",
        "    Returns:\n",
        "        str: The clean text content of the Wikipedia page, or an error message\n",
        "             if the page doesn't exist.\n",
        "\n",
        "    Note:\n",
        "        A custom user-agent string is required to comply with Wikipedia's\n",
        "        User-Agent policy. Make sure to replace the user-agent with your own\n",
        "        application details.\n",
        "\n",
        "    Example:\n",
        "        url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
        "        print(get_clean_wikipedia_text(url))\n",
        "\n",
        "    https://chatgpt.com/share/679bf411-23fc-8004-84cc-4e36746b9455\n",
        "    \"\"\"\n",
        "    # Initialize the Wikipedia API with a custom user agent and English language\n",
        "    wiki = wikipediaapi.Wikipedia(\n",
        "        language='en',\n",
        "        user_agent='YourAppName/1.0 (https://yourwebsite.com; contact@youremail.com)'\n",
        "    )\n",
        "\n",
        "    # Extract the page title from the URL\n",
        "    page_title = url.split('/')[-1]\n",
        "\n",
        "    # Fetch the page\n",
        "    page = wiki.page(page_title)\n",
        "\n",
        "    # Check if the page exists\n",
        "    if not page.exists():\n",
        "        return \"Page not found.\"\n",
        "\n",
        "    # Get the text from the page\n",
        "    clean_text = page.text\n",
        "\n",
        "    return clean_text"
      ],
      "metadata": {
        "id": "0oyzEcRuMJK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://en.wikipedia.org/wiki/Sustainability\"\n",
        "print(get_clean_wikipedia_text(url))"
      ],
      "metadata": {
        "id": "F9Z-Tz2FMJEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_AEEO7haYD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "This workshop provided a broad overview of different approaches to information extraction, their pros/cons and use cases, and offered some specific advice on how to use large language models (LLMs) for information extraction.\n",
        "\n",
        "There is much more to learn! You can take a look at our past workshops on [Artificial Intelligence for Research](https://github.com/nuitrcs/artificial_intelligence_for_research). You can also stay updated on future workshops [in our website](https://www.it.northwestern.edu/departments/it-services-support/research/research-events.html) or by subscribing to [our listserv](https://listserv.it.northwestern.edu/scripts/wa.exe?SUBED1=NUIT-research&A=1).\n",
        "\n",
        "If you're thinking of using LLMs for your research or are having trouble using one, [we're here to help you](https://app.smartsheet.com/b/form/2f2ec327e6164f83b588b7bbe2e2b56f)! üôÇ\n",
        "\n",
        "## Answers to the exercises\n",
        "\n",
        "**Exercise**"
      ],
      "metadata": {
        "id": "OxpA-ydHY9dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set context window to be used later\n",
        "CONTEXT_WINDOW = 75\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    abstract = row['abstract']\n",
        "    title = row['title']\n",
        "\n",
        "    search_term = \"water\"\n",
        "    # Lowercase abstract\n",
        "    lower_abstract = abstract.lower()\n",
        "\n",
        "    start_index = 0  # Keep track of where to search from\n",
        "\n",
        "    while True:\n",
        "        # Find the next occurrence of search term\n",
        "        # find() returns the index of the first occurrence of a subtring in a string\n",
        "        # https://www.geeksforgeeks.org/python-string-find/\n",
        "        match_index = lower_abstract.find(search_term, start_index)\n",
        "\n",
        "        # If search term not found\n",
        "        if match_index == -1:\n",
        "            break  # Exit loop if no more matches are found\n",
        "\n",
        "        print(\"===============================================================\")\n",
        "        print(f\"Title: {title}\")\n",
        "\n",
        "        # Get the match\n",
        "        match = lower_abstract[match_index:match_index + len(search_term)]\n",
        "        print(f\"Match: {match}\")\n",
        "\n",
        "        # Get the characters around the match\n",
        "        start = max(0, match_index - CONTEXT_WINDOW)  # Ensure start index is not negative\n",
        "        end = min(len(abstract), match_index + len(search_term) + CONTEXT_WINDOW)  # Ensure end index is within bounds\n",
        "        context = abstract[start:end]\n",
        "\n",
        "        print(f\"Context for match: {context}\")\n",
        "        print(\"==============================================================\\n\")\n",
        "\n",
        "        # Move start_index forward to continue searching after the current match\n",
        "        start_index = match_index + len(search_term)"
      ],
      "metadata": {
        "id": "KTZIsLDVoeAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**"
      ],
      "metadata": {
        "id": "N8cPP7IpaatN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pattern to search for\n",
        "# (?<=\\s) ‚Äì A positive lookbehind to ensure there is a space before the 4 digits\n",
        "# \\d{4} ‚Äì Matches exactly 4 digits\n",
        "# (?=\\s) ‚Äì A positive lookahead to ensure there is a space after the 4 digits\n",
        "pattern = r\"(?<=\\s)\\d{4}(?=\\s)\"\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  abstract = row['abstract']\n",
        "  # Find all occurrences of pattern and extract surrounding context\n",
        "  # re.finditer() searches for all matches of a pattern in a string and returns them as an iterator\n",
        "  # https://www.geeksforgeeks.org/re-finditer-in-python/\n",
        "  # Note: for keyword search we didn't necessarily need to use re.finditer()\n",
        "  matches = re.finditer(pattern, abstract, re.IGNORECASE)\n",
        "  # Iterate over matches\n",
        "  for each_match in matches:\n",
        "    print(\"===============================================================\")\n",
        "    print(f\"Title: {row['title']}\")\n",
        "    print(each_match.group())\n",
        "    # Get the characters around the match\n",
        "    start = max(0, each_match.start() - CONTEXT_WINDOW)  # Ensure start index is not negative\n",
        "    end = min(len(abstract), each_match.end() + CONTEXT_WINDOW)  # Ensure end index is within bounds\n",
        "    context = abstract[start:end]\n",
        "    print(f\"Context for match: {context}\")\n",
        "    print(\"==============================================================\\n\")"
      ],
      "metadata": {
        "id": "CSqPb8EEsF4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**"
      ],
      "metadata": {
        "id": "dxMNw6uJabWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df.sample(40, random_state=SEED).iterrows():\n",
        "  abstract = row['abstract']\n",
        "  for ent in nlp(abstract).ents:\n",
        "    if ent.label_ == \"PERSON\":\n",
        "      print(\"===============================================================\")\n",
        "      print(f\"Title of the paper: {row['title']}\")\n",
        "      print(f\"Text of the person: {ent.text}\")\n",
        "      start = max(0, ent.start_char - CONTEXT_WINDOW)  # Ensure start index is not negative\n",
        "      end = min(len(abstract), ent.end_char + CONTEXT_WINDOW)  # Ensure end index is within bounds\n",
        "      context = abstract[start:end]\n",
        "      print(f\"Context for match: {context}\")\n",
        "      print(\"==============================================================\\n\")"
      ],
      "metadata": {
        "id": "phVCjt172jlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**\n",
        "\n",
        "```\n",
        "Below I will provide the abstract of an article.\n",
        "\n",
        "Based on the text of the abstract, tell me the method(s) used in the article.\n",
        "\n",
        "If you are not sure, respond \"UNSURE\".\n",
        "\n",
        "Here is the abstract:\n",
        "```"
      ],
      "metadata": {
        "id": "6-BMOsygpvZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**\n",
        "\n",
        "Below are several examples of information extraction tasks in research. For each scenario, think about what approach you'd use and why.\n",
        "\n",
        "a) You are studying historical documents and need to extract references to specific historical figures, even when they are referred to indirectly (e.g., \"the first president\" referring to George Washington). -- **Possibly a combination of keyword search and LLM.**\n",
        "\n",
        "b) You need to extract standardized legal case citations (e.g., *Marbury v. Madison, 5 U.S. 137 (1803)*) from legal documents. -- **Regular expressions.**\n",
        "\n",
        "c) You are analyzing political speeches and want to identify mentions of specific policies (e.g., ‚ÄúMedicare for All‚Äù or ‚ÄúGreen New Deal‚Äù). -- **Possibly a combination of keyword search and LLM.**\n",
        "\n",
        "d) You need to extract company names and stock ticker symbols from financial news articles. -- **Pre-trained entity recognition models.**\n",
        "\n",
        "e) You are reviewing electronic health records to extract patient symptoms, even when they are described in different ways (e.g., ‚Äústomach pain,‚Äù ‚Äúabdominal discomfort,‚Äù ‚Äúache in the belly‚Äù). -- **Possibly a combination of keyword search and a pre-trained entity recognition model and/or an LLM.**\n",
        "\n",
        "f) You are studying sentiment in classic novels and need to identify passages that express themes of love and betrayal. -- **Possibly a combination of keyword search and LLM.**\n",
        "\n",
        "g) You are extracting inflation rates and GDP figures from economic reports. -- **Regular expressions.**\n",
        "\n",
        "h) You need to extract mentions of environmental disasters (e.g., ‚Äúoil spill,‚Äù ‚Äúwildfire‚Äù) from news reports. -- **Possibly a combination of keyword search and LLM.**\n",
        "\n",
        "i) You are scanning news articles to extract quotes from politicians. -- **Depending on format, regular expressions and/or LLM.**"
      ],
      "metadata": {
        "id": "Gz5X-BmOKxpQ"
      }
    }
  ]
}